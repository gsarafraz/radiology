{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['پنومونی',\n",
       " 'دوم',\n",
       " 'نوموتوراکس',\n",
       " 'متال',\n",
       " '34mm',\n",
       " 'مشهود',\n",
       " 'خارجی',\n",
       " 'تحتانی',\n",
       " '4',\n",
       " 'آمفیزم',\n",
       " 'جدا',\n",
       " 'ناکافی',\n",
       " 'دیگر',\n",
       " 'کوچک',\n",
       " 'مشکوک',\n",
       " 'قدیمی',\n",
       " 'منجر',\n",
       " 'شدید',\n",
       " '5',\n",
       " 'منتشر',\n",
       " 'همی',\n",
       " 'قدامی',\n",
       " 'سوم',\n",
       " 'دیافیز',\n",
       " None,\n",
       " 'مطرح',\n",
       " 'گرافی',\n",
       " 'مناسب',\n",
       " 'نامنظمی',\n",
       " 'فعال',\n",
       " 'جراحی،',\n",
       " 'مختصر',\n",
       " 'بزرگ',\n",
       " 'فوقانی',\n",
       " 'موجود',\n",
       " 'داخلی',\n",
       " 'پنجم',\n",
       " 'مفصل',\n",
       " 'چپ،',\n",
       " 'راست',\n",
       " 'همراه',\n",
       " 'دانسیته',\n",
       " 'چپ',\n",
       " 'بادی',\n",
       " '2',\n",
       " '35mm',\n",
       " 'متاکارپ',\n",
       " 'نرمال',\n",
       " 'فوق',\n",
       " 'مشابه',\n",
       " '31',\n",
       " 'ریوی',\n",
       " 'صعودی',\n",
       " 'استخوانی،',\n",
       " 'استخوانی',\n",
       " 'است،',\n",
       " 'قبلی',\n",
       " 'قابل',\n",
       " 'گردنی',\n",
       " 'م',\n",
       " 'ناشی',\n",
       " 'استرنوتومی',\n",
       " 'اخیر',\n",
       " 'مفصلی',\n",
       " 'اول',\n",
       " 'واسکلروتیک',\n",
       " 'جابجائی',\n",
       " 'ی',\n",
       " 'کنتراست',\n",
       " 'خفیف',\n",
       " 'میانی',\n",
       " 'منطبق',\n",
       " 'واضح',\n",
       " 'تقریبی',\n",
       " 'وshallowing',\n",
       " 'نرم',\n",
       " 'چند',\n",
       " 'دنده']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import parsivar\n",
    "\n",
    "data_path = '/Users/User/Desktop/radiology/data/'\n",
    "sentences = pd.read_excel(data_path + 'unique_sentences.xlsx')\n",
    "all_adj = []\n",
    "all_verbs = []\n",
    "\n",
    "\n",
    "for index, item in sentences.iterrows():\n",
    "    \n",
    "    sample = item['sentence']\n",
    "    my_tokenizer = parsivar.Tokenizer()\n",
    "    my_tagger = parsivar.POSTagger(tagging_model=\"wapiti\")  \n",
    "    tags = my_tagger.parse(my_tokenizer.tokenize_words(sample.translate(str.maketrans('', '', string.punctuation))))\n",
    "    func = lambda x: x[0] if ('ADJ' == x[1]) else None\n",
    "    adjs = np.array([func(tag) for tag in tags])\n",
    "    all_adj += list(adjs)\n",
    "    \n",
    "        \n",
    "all_adj = list(set(all_adj))\n",
    "print(len(all_adj))\n",
    "all_adj\n",
    "# def find_verbs(sent):\n",
    "#     sent = set(sent.split())\n",
    "#     return len(sent.intersection(set(body_parts)))\n",
    "\n",
    "# def find_adject(sent):\n",
    "#     sent = set(sent.split())\n",
    "#     return sent.intersection(set(body_parts))\n",
    "\n",
    "# sentences['num_body_parts'] = sentences['sentence'].apply(lambda x:find_body_parts_len(x))\n",
    "# sentences['body_parts'] = sentences['sentence'].apply(lambda x:find_body_parts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.Preprocessing import Preprocessing\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "\n",
    "data_path = '/Users/User/Desktop/radiology/data/'\n",
    "preprocessing = Preprocessing(data_folder = data_path)\n",
    "\n",
    "diseases = list(pd.read_csv(data_path + 'diseases_third_version.csv')['Term'])\n",
    "base_types_diseases = list(pd.read_csv(data_path + 'diseases_third_version.csv')['baseType'])\n",
    "body_parts = list(pd.read_csv(data_path + 'body_parts_second_version.csv')['Term'])\n",
    "diseases = list([preprocessing.complete_normalization(x) for x in diseases])[1:]\n",
    "base_types_diseases = list([preprocessing.complete_normalization(x) for x in base_types_diseases])[1:]\n",
    "body_parts = list(set([preprocessing.complete_normalization(x) for x in body_parts]))[1:]\n",
    "\n",
    "diseases_df = pd.DataFrame({'term':diseases, 'baseType': base_types_diseases})\n",
    "body_parts_df = pd.DataFrame({'term':body_parts})\n",
    "\n",
    "diseases_df_tmp = pd.DataFrame()\n",
    "\n",
    "for index, row in diseases_df.iterrows():\n",
    "    term = row['term']\n",
    "    baseType = row['baseType']\n",
    "    words = term.split()\n",
    "    for word in words:\n",
    "        diseases_df_tmp2 = {'term': [term.replace(word, word + 'های'), term.replace(word, word + 'ی'), term.replace(word, word + 'ها')], 'baseType': [baseType for i in range(3)]}\n",
    "        diseases_df_tmp2 = pd.DataFrame(data=diseases_df_tmp2)\n",
    "        diseases_df_tmp = pd.concat([diseases_df_tmp, diseases_df_tmp2], axis=0)\n",
    "    \n",
    "diseases_df = pd.concat([diseases_df_tmp, diseases_df], axis=0)\n",
    "\n",
    "def count_subwords(word):\n",
    "    return len(word.split())\n",
    "\n",
    "diseases_df['num_subwords'] = diseases_df['term'].apply(lambda x: count_subwords(x))\n",
    "body_parts_df['num_subwords'] = body_parts_df['term'].apply(lambda x: count_subwords(x))\n",
    "\n",
    "max_subwords = max(body_parts_df['num_subwords'].max(), diseases_df['num_subwords'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>baseType</th>\n",
       "      <th>num_subwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شکستگیهای انفجاری</td>\n",
       "      <td>شکستگی انفجاری</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>شکستگیی انفجاری</td>\n",
       "      <td>شکستگی انفجاری</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>شکستگیها انفجاری</td>\n",
       "      <td>شکستگی انفجاری</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شکستگی انفجاریهای</td>\n",
       "      <td>شکستگی انفجاری</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>شکستگی انفجاریی</td>\n",
       "      <td>شکستگی انفجاری</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>adenoma</td>\n",
       "      <td>ادنوما</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>fx</td>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>فرکچر</td>\n",
       "      <td>شکستگی</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ضایعه اسکلروتیک</td>\n",
       "      <td>اسکلروتیک</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>انحراف</td>\n",
       "      <td>انحراف</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 term        baseType  num_subwords\n",
       "0   شکستگیهای انفجاری  شکستگی انفجاری             2\n",
       "1     شکستگیی انفجاری  شکستگی انفجاری             2\n",
       "2    شکستگیها انفجاری  شکستگی انفجاری             2\n",
       "0   شکستگی انفجاریهای  شکستگی انفجاری             2\n",
       "1     شکستگی انفجاریی  شکستگی انفجاری             2\n",
       "..                ...             ...           ...\n",
       "46            adenoma          ادنوما             1\n",
       "47                 fx              fx             1\n",
       "48              فرکچر          شکستگی             1\n",
       "49    ضایعه اسکلروتیک       اسکلروتیک             2\n",
       "50             انحراف          انحراف             1\n",
       "\n",
       "[264 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diseases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'          گزارش رادیولوژی _x0007_     سند : FO-MR-78               ویرایش :   1/4/92                 ویرایش :         1   _x0007_ _x0007_شماره برگه : _x0007_226909 _x0007_شماره پرونده: _x0007_ _x0007_ _x0007_کدشناسایی: _x0007_2628681 _x0007_کدپذیرش: _x0007_5254982 _x0007_ _x0007_مشخصات بیمار: _x0007_کلثوم   شکوری _x0007_تاریخ وساعت برگه: _x0007_04/01/1399   06:06 _x0007_ _x0007_ _x0007_ _x0007_تاریخ وساعت  گزارش: _x0007_1399/01/04 13:58 _x0007_ _x0007_سن : _x0007_69 _x0007_نوع بیمه : _x0007_تامین اجتماعی مستمری و کارکنان سازمان _x0007_بخش: _x0007_اورژانس داخلی _x0007_ _x0007_ رادیوگرافی قفسه صدری نمای روبرو یا نیمرخ و یا هر نمای دیگر (یک فیلم )  رادیوگرافی ساده شکم خوابیده وایستاده دو فیلم  گزارش و نظریه رادیولوژیست : رادیوگرافی ریه: کاردیومگالی دارد. برجستگی و کلسیفیکاسیون قوس آئورت مشهود است. djd توراسیک و تصویر کدورت های رتیکولر ریتین بویژه در زون های تحتانی دو طرف رویت میشود. تشخیص های افتراقی aspiration pneumonia و atypic pneumonia را در درجه اول برای بیمار مطرح میکند .  رادیوگرافی شکم: تصویر سنگ در مسیر سیستم ادراری مشاهده نشد. کلسیفیکاسیون در شکم وجود ندارد. نمای گاز روده ای نرمال است. djd لومبار مشهود است. لذا تطابق با یافته های بالینی و آزمایشگاهی از نظر تائید تشخیص و اقدامات مقتضی توصیه میگردد. /ج    راديولوژيست: دکتر مریم حقیقی مراد                                                                                 دستيار راديولوژی                                                                                  دکتر احمد زاده   _x0007_ _x0007_گزارش بدون مهر و امضاء پزشک مربوطه فاقد اعتبار می باشد '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = '/Users/User/Desktop/radiology/data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = list(pd.read_csv(data_path + 'diseases_third_version.csv')['Term'])\n",
    "base_types_diseases = list(pd.read_csv(data_path + 'diseases_third_version.csv')['baseType'])\n",
    "body_parts = list(pd.read_csv(data_path + 'body_parts_second_version.csv')['Term'])\n",
    "diseases = list([preprocessing.complete_normalization(x) for x in diseases])[1:]\n",
    "base_types_diseases = list([preprocessing.complete_normalization(x) for x in base_types_diseases])[1:]\n",
    "body_parts = list(set([preprocessing.complete_normalization(x) for x in body_parts]))[1:]\n",
    "\n",
    "diseases_df = pd.DataFrame({'term':diseases, 'baseType': base_types_diseases})\n",
    "body_parts_df = pd.DataFrame({'term':body_parts})\n",
    "\n",
    "diseases_df_tmp = pd.DataFrame()\n",
    "\n",
    "for index, row in diseases_df.iterrows():\n",
    "    term = row['term']\n",
    "    baseType = row['baseType']\n",
    "    words = term.split()\n",
    "    for word in words:\n",
    "        diseases_df_tmp2 = {'term': [term.replace(word, word + 'های'), term.replace(word, word + 'ی'), term.replace(word, word + 'ها')], 'baseType': [baseType for i in range(3)]}\n",
    "        diseases_df_tmp2 = pd.DataFrame(data=diseases_df_tmp2)\n",
    "        diseases_df_tmp = pd.concat([diseases_df_tmp, diseases_df_tmp2], axis=0)\n",
    "    \n",
    "diseases_df = pd.concat([diseases_df_tmp, diseases_df], axis=0)\n",
    "\n",
    "def count_subwords(word):\n",
    "    return len(word.split())\n",
    "\n",
    "diseases_df['num_subwords'] = diseases_df['term'].apply(lambda x: count_subwords(x))\n",
    "body_parts_df['num_subwords'] = body_parts_df['term'].apply(lambda x: count_subwords(x))\n",
    "\n",
    "max_subwords = max(body_parts_df['num_subwords'].max(), diseases_df['num_subwords'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "neg_verbs = ['نشد', 'نمیشود','نمی‌شود','نمی شود', 'ندارند','نبود','نگردد','نباشد', 'نگردید', 'نمیتواند', 'نمی‌تواند','ندارد','نمی تواند','نیست','نمی']\n",
    "\n",
    "def find_polarity(sent):\n",
    "    \n",
    "    for verb in neg_verbs:\n",
    "        if(verb in sent):\n",
    "            return 'منفی'\n",
    "    return 'مثبت'\n",
    "    \n",
    "    \n",
    "def find_shared_body_parts_and_diseases(sent):\n",
    "    \n",
    "    shared_body_parts = []\n",
    "    shared_disease = []\n",
    "    shared_disease_bt = []\n",
    "    count_subwords = max_subwords\n",
    "    \n",
    "    while(count_subwords > 0):\n",
    "        \n",
    "        n_grams = ngrams(sequence = sent.split(), n = count_subwords)\n",
    "        grams_list = []\n",
    "        for grams in n_grams:\n",
    "            grams_list.append(' '.join(grams))\n",
    "            \n",
    "        grams_list = list(set(grams_list))\n",
    "            \n",
    "        shared_bodyparts_tmp  = list(body_parts_df[(body_parts_df['num_subwords']  == count_subwords) & (body_parts_df['term'].isin(grams_list))]['term'])\n",
    "        shared_diseases_tmp_bt = list(diseases_df[(diseases_df['num_subwords'] == count_subwords) & (diseases_df['term'].isin(grams_list))]['baseType'])\n",
    "        shared_diseases_tmp = list(diseases_df[(diseases_df['num_subwords'] == count_subwords) & (diseases_df['term'].isin(grams_list))]['term'])\n",
    "        \n",
    "        for word in shared_bodyparts_tmp:\n",
    "            sent = sent.replace(word, '')\n",
    "            \n",
    "        for word in shared_diseases_tmp:\n",
    "            sent = sent.replace(word, '')\n",
    "            \n",
    "        shared_body_parts += shared_bodyparts_tmp\n",
    "        shared_disease += shared_diseases_tmp\n",
    "        shared_disease_bt += shared_diseases_tmp_bt\n",
    "        count_subwords -= 1\n",
    "    \n",
    "    return shared_body_parts, shared_disease, shared_disease_bt\n",
    "\n",
    "def find_prev_tag(sentenceslist, sentindx):\n",
    "    \n",
    "    tag = None\n",
    "    sentenceslist = sentenceslist[:sentindx]\n",
    "    for i in range(1,sentindx+1):\n",
    "        sent = sentenceslist[-1*i]\n",
    "        if('tag' in sent):\n",
    "            intersect = list(set(sent.split()).intersection(body_parts))\n",
    "            if(len(intersect) > 0):\n",
    "                tag = intersect[0]\n",
    "            break\n",
    "    return tag\n",
    "    \n",
    "    \n",
    "def bodypart_disease_alignment(sentenceslist):\n",
    "    all_results = []\n",
    "    \n",
    "    for sentindx, sent in enumerate(sentenceslist):\n",
    "        result = []\n",
    "        shared_bodyparts, shared_diseases, shared_diseases_bt = find_shared_body_parts_and_diseases(sent)\n",
    "        polarity = find_polarity(sent)\n",
    "        \n",
    "        if(len(shared_diseases) != 0):\n",
    "            \n",
    "            if(len(shared_bodyparts) == 0):\n",
    "                tag = find_prev_tag(sentenceslist, sentindx)\n",
    "                for index, disease in enumerate(shared_diseases):\n",
    "                        result.append({'عارضه':shared_diseases_bt[index],'عضو':tag, 'رخداد یا عدم رخداد': polarity})\n",
    "                \n",
    "            else:\n",
    "                index_bps = [sent.index(x) for x in shared_bodyparts]\n",
    "                index_diseases = [sent.index(x) for x in shared_diseases]\n",
    "        \n",
    "                for index, d_index in enumerate(index_diseases):\n",
    "                    \n",
    "                    tmp_arr = np.abs(np.array(index_bps) - d_index)\n",
    "                    bp_min_index = np.argmin(tmp_arr)\n",
    "                    result.append({'عارضه':shared_diseases_bt[index],'عضو':shared_bodyparts[bp_min_index], 'رخداد یا عدم رخداد': polarity})\n",
    "        \n",
    "        if(len(result) > 0):\n",
    "            all_results.append(result)\n",
    "    return all_results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:  رادیوگرافی ریه: کاردیومگالی دارد. برجستگی کلسیفیکیشن قوس ایورت مشهود است. djd توراسیک تصویر کدورت های رتیکولر ریتین بویژه زون های 2 رویت میشود. تشخیص های افتراقی aspiration pneumonia atypic pneumonia درجه بیمار مطرح میکند. رادیوگرافی شکم: تصویر سنگ مسیر سیستم ادراری مشاهده نشد. کلسیفیکیشن شکم وجود ندارد. گاز روده طبیعی است. djd لومبار مشهود است. لذا تطابق یافته.های بالینی ازمایشگاهی نظر تایید تشخیص اقدامات مقتضی توصیه میگردد.\n",
      "1) 'عارضه': 'کلسیفیکیشن', 'عضو': 'قوس ایورت', 'رخداد یا عدم رخداد': 'مثبت'\n",
      "2) 'عارضه': 'ارتروز', 'عضو': 'ریه', 'رخداد یا عدم رخداد': 'مثبت'\n",
      "3) 'عارضه': 'سنگ', 'عضو': 'سیستم ادراری', 'رخداد یا عدم رخداد': 'منفی'\n",
      "4) 'عارضه': 'کلسیفیکیشن', 'عضو': 'شکم', 'رخداد یا عدم رخداد': 'منفی'\n",
      "5) 'عارضه': 'ارتروز', 'عضو': 'شکم', 'رخداد یا عدم رخداد': 'مثبت'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.Preprocessing import Preprocessing\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "data_path = '/Users/User/Desktop/radiology/data/'\n",
    "preprocessing = Preprocessing(data_folder = data_path)\n",
    "\n",
    "data = pd.read_excel(data_path + 'cleaned_tokenized_report.xlsx')\n",
    "\n",
    "\n",
    "def print_result(report):\n",
    "    count = 1\n",
    "    all_results = ''\n",
    "    for element in report:\n",
    "        all_results += str(count) + \") \" + str(element) + '\\n'\n",
    "        count += 1\n",
    "    all_results = all_results.replace('[','').replace(']','').replace('{','').replace('}','')\n",
    "    print(all_results)\n",
    "    \n",
    "def summarize_radiology_report(report):\n",
    "\n",
    "    report = preprocessing.cleaner(report)\n",
    "    report = preprocessing.complete_normalization(report)\n",
    "    report = preprocessing.sentence_tokenizer(report)\n",
    "    print_result(bodypart_disease_alignment(report))\n",
    "    \n",
    "summarize_radiology_report(data.iloc[40]['توضیحات پزشک'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['قفسه صدری دیگر 1 فیلم رادیوگرافی ساده شکم خوابیده ایستاده 2 فیلم رادیوگرافی ریه tag  .', 'کاردیومگالی دارد .', ' برجستگی کلسیفیکیشن قوس ایورت مشهود است .', ' djd توراسیک تصویر کدورت های رتیکولر ریتین بویژه زون های 2 رویت میشود .', ' تشخیص های افتراقی aspiration pneumonia atypic pneumonia درجه بیمار مطرح میکند .', ' رادیوگرافی شکم tag  .', 'تصویر سنگ مسیر سیستم ادراری مشاهده نشد .', ' کلسیفیکیشن شکم وجود ندارد .', ' گاز روده طبیعی است .', ' djd لومبار مشهود است .', ' لذا تطابق یافته .', 'های بالینی ازمایشگاهی نظر تایید تشخیص اقدامات مقتضی توصیه میگردد .']\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = '/Users/User/Desktop/radiology/data/'\n",
    "data = pd.read_excel(data_path + 'cleaned_tokenized_report.xlsx')\n",
    "data.iloc[40]['tokenized_report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "  \n",
    "# Top level window\n",
    "frame = tk.Tk()\n",
    "frame.title(\"TextBox Input\")\n",
    "frame.geometry('1000x200')\n",
    "# Function for getting Input\n",
    "# from textbox and printing it \n",
    "# at label widget\n",
    "  \n",
    "def printInput():\n",
    "    inp = inputtxt.get(1.0, \"end-1c\")\n",
    "    lbl.config(text = \"Provided Input: \"+inp)\n",
    "  \n",
    "# TextBox Creation\n",
    "inputtxt = tk.Text(frame,\n",
    "                   height = 5,\n",
    "                   width = 800)\n",
    "  \n",
    "inputtxt.pack()\n",
    "  \n",
    "# Button Creation\n",
    "printButton = tk.Button(frame,\n",
    "                        text = \"Summarize The Report\", \n",
    "                        command = printInput)\n",
    "printButton.pack()\n",
    "  \n",
    "# Label Creation\n",
    "lbl = tk.Label(frame, text = \"\")\n",
    "lbl.pack()\n",
    "frame.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
